{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo de `word2vec` con `gensim`\n",
    "\n",
    "\n",
    "En la siguiente celda, importamos las librerías necesarias y configuramos los mensajes de los logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim, logging, os\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento de un modelo\n",
    "\n",
    "Implemento una clase `Corpus` con un iterador sobre un directorio que contiene ficheros de texto. Utilizaré una instancia de `Corpus` para poder procesar de manera más eficiente una colección, sin necesidad de cargarlo previamente en memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Corpus(object):\n",
    "    '''Clase Corpus que permite leer de manera secuencial un directorio de documentos de texto'''\n",
    "    \n",
    "    def __init__(self, directorio):\n",
    "        self.directory = directorio\n",
    "\n",
    "    def __iter__(self):\n",
    "        for fichero in os.listdir(self.directory):\n",
    "            for linea in open(os.path.join(self.directory, fichero)):\n",
    "                yield linea.split()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`CORPUSDIR` contiene una colección de noticias en español (normalizada previamente a minúsculas y sin signos de puntuación) con alrededor de 150 millones de palabras. Entrenamos un modelo en un solo paso, ignorando aquellos tokens que aparecen menos de 10 veces, para descartar erratas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CORPUSDIR = 'PATH_TO_YOUR_CORPUS_DIRECTORY'\n",
    "oraciones = Corpus(CORPUSDIR)\n",
    "model = gensim.models.Word2Vec(oraciones, min_count=10, size=150, workers=2)\n",
    "\n",
    "# el modelo puede entrenarse en dos pasos sucesivos pero por separado\n",
    "#model = gensim.models.Word2Vec() # modelo vacío\n",
    "#model.build_vocab(oraciones)  # primera pasada para crear la lista de vocabulario\n",
    "#model.train(other_sentences)  # segunda pasada para calcula vectores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez completado el entrenamiento (después de casi 30 minutos), guardamos el modelo en disco. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('PATH_TO_YOUR_MODEL.w2v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el futuro, podremos utilizar este modelo cargándolo en memoria con la instrucción:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-02-23 15:44:48,139 : INFO : loading Word2Vec object from /data/w2v/efe-150.w2v\n",
      "2018-02-23 15:44:49,605 : INFO : loading wv recursively from /data/w2v/efe-150.w2v.wv.* with mmap=None\n",
      "2018-02-23 15:44:49,607 : INFO : loading vectors from /data/w2v/efe-150.w2v.wv.vectors.npy with mmap=None\n",
      "2018-02-23 15:44:49,754 : INFO : setting ignored attribute vectors_norm to None\n",
      "2018-02-23 15:44:49,756 : INFO : loading vocabulary recursively from /data/w2v/efe-150.w2v.vocabulary.* with mmap=None\n",
      "2018-02-23 15:44:49,756 : INFO : loading trainables recursively from /data/w2v/efe-150.w2v.trainables.* with mmap=None\n",
      "2018-02-23 15:44:49,757 : INFO : loading syn1neg from /data/w2v/efe-150.w2v.trainables.syn1neg.npy with mmap=None\n",
      "2018-02-23 15:44:49,903 : INFO : setting ignored attribute cum_table to None\n",
      "2018-02-23 15:44:49,905 : INFO : loaded /data/w2v/efe-150.w2v\n"
     ]
    }
   ],
   "source": [
    "#model = gensim.models.Word2Vec.load('PATH_TO_YOUR_MODEL.w2v')\n",
    "#model = gensim.models.Word2Vec.load('/data/w2v/eswiki-280.w2v')\n",
    "model = gensim.models.Word2Vec.load('/data/w2v/efe-150.w2v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probando nuestro modelo\n",
    "\n",
    "El objeto `model` contiene una enorme matriz de números: una tabla, donde cada fila es uno de los términos del vocabulario reconocido y cada columna es una de las características que permiten modelar el significado de dicho término.\n",
    "\n",
    "En nuestro modelo, tal y como está entrenado, tenemos más de 26 millones de términos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26511278\n"
     ]
    }
   ],
   "source": [
    "print(model.corpus_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada término del vocabulario está representado como un vector con 150 dimensiones: 105 características. Podemos acceder al vector de un término concreto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.23375803  0.7407618   0.62846696 -0.2483204  -1.3737258  -0.590827\n",
      "  0.6523226   3.4684708   1.7477489  -1.3163776   0.82081383  0.20853145\n",
      "  0.7314245   0.13800569  1.1055775  -0.57149947 -1.1715975  -1.193085\n",
      " -0.58984065  1.0502697   0.74993986  0.34181598 -0.0588204   0.4395582\n",
      "  0.76400846 -1.9379612   1.1530447   0.44922572  0.82149845  0.26971048\n",
      " -0.38326746 -1.758451   -0.5402964  -0.98902136 -1.1511512  -1.4542484\n",
      " -2.0532486  -0.84603715  1.1789035   0.8954198  -0.07105764 -0.6009114\n",
      " -0.32276174 -0.5073711  -0.72784954 -1.0411621   0.7728746   0.9850062\n",
      "  1.5772941  -1.6976876   1.010405   -0.8032998   1.3950039   1.461288\n",
      "  1.6583639  -0.01957864  0.72737986  1.2166173  -0.7563755  -0.49769273\n",
      " -1.0798682   0.7831595  -0.7357984   2.294056   -0.3698049  -2.173252\n",
      "  0.9841621   0.27959237 -0.12817219  0.48054722  1.4299809  -1.2538192\n",
      "  1.4374963   0.7781263  -0.33234715 -0.8497048  -0.21231754  2.2888587\n",
      " -1.5101597   0.5487344  -1.305364   -0.4762724  -2.3166475  -0.55565095\n",
      " -0.37213114  0.0829507  -1.4931779   0.18941547 -0.20204468 -1.3067802\n",
      "  1.185134    0.47404918 -0.02560972 -1.0067849   0.342525    0.7240906\n",
      " -0.37065524  0.424106    0.82902807  1.7843691   0.17454833  0.5679473\n",
      "  0.50372005  0.27411127 -0.23873948  0.46582544 -1.5172936   0.88242686\n",
      "  1.7371198   0.20801589 -0.36779287  0.40990466  1.9687264  -0.71215713\n",
      "  0.08861663  0.2969956  -1.5700237  -1.0185002  -1.219388   -1.3530422\n",
      " -0.00662348 -1.118937    0.13815479  1.0552286   1.5794694   1.0089911\n",
      " -1.8139915   1.3118014  -0.54552054  0.3711891   0.6764692   0.44065475\n",
      " -0.2532436  -0.61026263  1.1887282  -3.6361747  -1.3917662   0.7092135\n",
      "  1.3247883  -0.30382457 -1.3756948   0.9213571  -1.0597266   0.39357576\n",
      " -0.9723017  -0.13086636 -0.81142306  0.6865045   1.5298002   0.5777973 ] \n",
      "\n",
      "[-1.585878   -0.9379715  -0.13159156 -1.7260168  -2.032544   -0.45080382\n",
      "  1.8171105   1.0297425   0.9800345  -0.7266191   1.1491116   0.28175578\n",
      "  0.74200004  2.3931203  -2.0383203  -1.2089862  -0.575934   -1.544867\n",
      " -0.40107933 -0.2009654  -0.2683494  -0.06166422 -0.28822362  0.09572475\n",
      "  2.5944545  -2.0366738   2.2084937   0.55596876  1.0165557   0.25502396\n",
      "  0.91827726 -1.6429708  -1.5559933  -0.9771576  -0.26599073 -2.1131964\n",
      " -0.9803386  -0.82595074  0.4861428  -0.63914144 -1.1116362  -1.2688785\n",
      " -1.8304402   0.8239117  -0.44300762 -1.2925302   1.9375533   0.32335404\n",
      "  1.0324135  -1.4600004   0.9453387  -0.41532388  0.4751093   1.2293277\n",
      "  0.97148216  1.0014237  -0.15042607 -0.17148307  1.5319511  -1.0035038\n",
      " -0.60405374  0.80785877  0.05210643  1.0339969  -0.47035128 -0.04087571\n",
      "  1.2217722  -0.85886574  0.34465235  1.4384885   0.55363774  0.3078235\n",
      "  0.14110799 -0.5199924  -1.7349062  -1.2413516  -0.63787234  0.40051454\n",
      "  0.69453573 -0.13476963 -2.0891664  -1.561698   -0.54649675  0.18888941\n",
      "  0.4393693  -0.18649471  1.1060543   0.10543153 -0.29416808 -1.0613333\n",
      "  1.3003973   0.37398383 -1.310591   -1.1635894   0.10426329  2.0679507\n",
      " -2.6314747   0.6737883   2.076767    1.08134     0.52947325 -0.21450524\n",
      "  2.2634351   3.0140858  -0.83950305 -0.78787005 -1.4983637   0.15598716\n",
      "  0.5264594   0.04323687 -0.45705163 -1.0113888   1.998688    0.3225145\n",
      " -0.70522016  0.31383538 -0.5318488  -1.5409585  -0.76519257 -1.8905514\n",
      "  0.07749848 -0.9826515   1.0741658   1.4682081   1.3787637   2.2244248\n",
      " -0.14520836 -0.0838449   1.8091714   1.8723446   0.33478683 -0.18573336\n",
      " -0.12759718 -2.9351811   0.35500526  1.0414389  -1.4989673  -1.2908633\n",
      "  1.1054726   0.15647627  1.3160697  -0.27796552 -0.01520971 -0.8700874\n",
      " -2.31204    -0.7146805   0.75804317  0.82237285  1.659205    0.47048202] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"word 'microsoft' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f954d6f7c5b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'verde'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'microsoft'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/utils.py\u001b[0m in \u001b[0;36mnew_func1\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1366\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m                 )\n\u001b[0;32m-> 1368\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_func1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, words)\u001b[0m\n\u001b[1;32m    819\u001b[0m         \u001b[0mRefer\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdocumentation\u001b[0m \u001b[0;32mfor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeyedvectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWord2VecKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m         \"\"\"\n\u001b[0;32m--> 821\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdeprecated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Method will be removed in 4.0.0, use self.wv.__contains__() instead\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, entities)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;31m# allow calls like trained_model['office'], as a shorthand for trained_model[['office']]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwords_closer_than\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"word 'microsoft' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "print(model['azul'], '\\n')\n",
    "\n",
    "print(model['verde'], '\\n')\n",
    "\n",
    "print(model['microsoft'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Estos vectores no nos dicen mucho, salvo que contienen números muy pequeños :-/\n",
    "\n",
    "El mismo objeto `model` permite acceder a una serie de funcionalidades ya implementadas que nos van a permitir evaluar formal e informalmente el modelo. Por el momento, nos contentamos con los segundo: vamos a revisar visualmente los significados que nuestro modelo ha aprendido por su cuenta. \n",
    "\n",
    "Podemos calcular la similitud semántica entre dos términos usando el método `similarity`, que nos devuelve un número entre 0 y 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hombre - mujer 0.4590373348196588\n",
      "perro - gato 0.8069666086573097\n",
      "gato - periódico 0.3945044491661706\n"
     ]
    }
   ],
   "source": [
    "print('hombre - mujer', model.wv.similarity('hombre', 'mujer'))\n",
    "\n",
    "print('perro - gato', model.wv.similarity('perro', 'gato'))\n",
    "\n",
    "print('gato - periódico', model.wv.similarity('gato', 'periódico'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos seleccionar el término que no encaja a partir de una determinada lista de términos usando el método `doesnt_match`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-02-23 15:46:24,991 : WARNING : vectors for words {'gonzález', 'washington'} are not present in the model, ignoring these words\n",
      "2018-02-23 15:46:24,997 : WARNING : vectors for words {'pp', 'psoe', 'ciu', 'epi'} are not present in the model, ignoring these words\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en la lista madrid barcelona gonzález washington sobra: barcelona\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot select a word from an empty list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-68e8bc2ec60d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlista2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'psoe pp ciu epi'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en la lista'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlista2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sobra:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoesnt_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlista2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mlista3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'publicaron declararon soy negaron'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mdoesnt_match\u001b[0;34m(self, words)\u001b[0m\n\u001b[1;32m    615\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"vectors for words %s are not present in the model, ignoring these words\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignored_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mused_words\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 617\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot select a word from an empty list\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m         \u001b[0mvectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mused_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mREAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m         \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munitvec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mREAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot select a word from an empty list"
     ]
    }
   ],
   "source": [
    "lista1 = 'madrid barcelona gonzález washington'.split()\n",
    "print('en la lista', ' '.join(lista1), 'sobra:', model.wv.doesnt_match(lista1))\n",
    "\n",
    "#lista2 = 'psoe pp ciu epi'.split()\n",
    "#print('en la lista', ' '.join(lista2), 'sobra:', model.wv.doesnt_match(lista2))\n",
    "\n",
    "lista3 = 'publicaron declararon soy negaron'.split()\n",
    "print('en la lista', ' '.join(lista3), 'sobra:', model.wv.doesnt_match(lista3))\n",
    "\n",
    "lista3 = 'homero saturno cervantes shakespeare cela'.split()\n",
    "print('en la lista', ' '.join(lista3), 'sobra:', model.wv.doesnt_match(lista3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos buscar los términos más similares usando el método `most_similar` de nuestro modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"word 'microsoft' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-3e7a49beffac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mterminos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'==>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    358\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                     \u001b[0mall_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"word 'microsoft' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "terminos = 'psoe chicago sevilla aznar podemos estuvieron'.split()\n",
    "terminos = 'microsoft ibm iberia repsol'.split()\n",
    "\n",
    "for t in terminos:\n",
    "    print(t, '==>', model.wv.most_similar(t), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el mismo método `most_similar` podemos combinar vectores de palabras tratando de jugar con los rasgos semánticos de cada una de ellas para descubrir nuevas relaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('==> alcalde + mujer - hombre')\n",
    "most_similar = model.wv.most_similar(positive=['alcalde', 'mujer'], negative=['hombre'], topn=3)\n",
    "for item in most_similar:\n",
    "    print(item)\n",
    "\n",
    "print('==> madrid + filipinas - españa')\n",
    "most_similar = model.wmost_similar(positive=['madrid', 'filipinas'], negative=['españa'], topn=3)\n",
    "for item in most_similar:\n",
    "    print(item)\n",
    "\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
